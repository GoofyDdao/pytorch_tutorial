{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software vs Machine Learning\n",
    "\n",
    "![](img/software_vs_ml.png)\n",
    "\n",
    "![](img/ml_debt.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Widget to visualize linear regression, error, and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, slope: float, bias: float):\n",
    "    \"\"\"A simple linear model.\"\"\"\n",
    "    return x * slope + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err2(pred, true):\n",
    "    return (true - pred) ** 2\n",
    "\n",
    "def mse(pred, true):\n",
    "    return np.mean(err2(pred, true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "std = 4\n",
    "\n",
    "x = np.linspace(-10, 10, 20)\n",
    "noise = np.random.normal(0, 2, size=n)\n",
    "\n",
    "y = f(x, slope=1.3, bias=5) + noise\n",
    "\n",
    "data = pd.DataFrame({\"x\": x, \"y\": y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_dom = np.linspace(-2, 4.5, 66)\n",
    "slope_losses = {\n",
    "    _slope: mse(f(x, _slope, bias=5), y)\n",
    "    for _slope in slope_dom\n",
    "}\n",
    "df_slope_losses = pd.DataFrame({\n",
    "    \"slope\": slope_losses.keys(),\n",
    "    \"loss\": slope_losses.values(),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RendererRegistry.enable('altair_viewer')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.renderers.enable('altair_viewer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lin_reg(\n",
    "    slope: float,\n",
    "    bias: float,\n",
    "    show_pred=True,\n",
    "    show_err=True,\n",
    "    show_err2=False,\n",
    "    show_loss_landscape=False,\n",
    "):\n",
    "    \n",
    "    pred = x * slope + bias\n",
    "    \n",
    "    data[\"pred\"] = pred\n",
    "    data[\"err\"] = y - pred\n",
    "    data[\"err2\"] = (y - pred) ** 2\n",
    "    data[\"x2\"] = x - data[\"err\"]\n",
    "\n",
    "    mse = np.mean(data['err2'])\n",
    "    mae = np.mean(np.abs(data['err']))\n",
    "    \n",
    "    chart = (\n",
    "        alt.Chart(data)\n",
    "        .mark_point()\n",
    "        .encode(x=\"x\", y=\"y\")\n",
    "        .properties(title=f\"Lin Reg | MSE: {mse:5.01f} | MAE: {mae:5.02f}\")\n",
    "    )\n",
    "    if show_pred:\n",
    "        chart += (\n",
    "            alt.Chart(data)\n",
    "            .mark_line()\n",
    "            .encode(x=\"x\", y=\"pred\")\n",
    "        )\n",
    "    if show_err:\n",
    "        chart += (\n",
    "            alt.Chart(data)\n",
    "            .mark_line()\n",
    "            .encode(x=\"x\", y=\"y\", y2=\"pred\")\n",
    "\n",
    "        )\n",
    "    if show_err2:\n",
    "        chart += (\n",
    "            alt.Chart(data)\n",
    "            .mark_rect(fill=\"none\", stroke=\"red\")\n",
    "            .encode(x=\"x\", y=\"y\", x2=\"x2\", y2=\"pred\")\n",
    "\n",
    "        )\n",
    "    \n",
    "\n",
    "    if not show_loss_landscape:\n",
    "        return chart\n",
    "    \n",
    "    _chart_loss = (\n",
    "        alt.Chart(df_slope_losses)\n",
    "        .mark_line()\n",
    "        .encode(x=\"slope\", y=\"loss\")\n",
    "        .properties(title=\"Loss Landscape (slope)\")\n",
    "    )\n",
    "    _chart_loss_hl = (\n",
    "        alt.Chart(pd.DataFrame({\"x\": [slope], \"y\": [0], \"y2\": [400]}))\n",
    "        .mark_line()\n",
    "        .encode(x=\"x\", y=\"y\", y2=\"y2\")\n",
    "    )\n",
    "    return chart | (_chart_loss + _chart_loss_hl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_lin_reg(\n",
    "#     slope=.3,\n",
    "#     bias=8,\n",
    "#     show_pred=True,\n",
    "#     show_err=True,\n",
    "#     show_err2=False,\n",
    "# )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e70452565f4ad4ad936faa74f07178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='slope', max=2.0, min=-2.0), FloatSlider(value=0.0, dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_lin_reg(slope: float, bias: float, show_pred=True, show_err=True, show_err2=False, show_loss_landscape=False)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipywidgets.interact(\n",
    "    show_lin_reg,\n",
    "    slope=(-2.0, 2.0),\n",
    "    bias=(-8.0, 8.0),\n",
    "    show_pred=True,\n",
    "    show_err=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression - more formally\n",
    "\n",
    "0. Data\n",
    "\n",
    "\n",
    "1. Model:\n",
    "  - $f(X) = X \\beta = \\hat y$\n",
    "\n",
    "\n",
    "2. Loss / criterion:\n",
    "  - $ err_i = y_i - f(X_i)$\n",
    "  - $MSE = \\frac{1}{n} \\sum_{i=1}^{N} err_i^2$\n",
    "\n",
    "\n",
    "3. Optimize:\n",
    "  - minimize the MSE yields the optimal $\\hat\\beta$ (after doing some math)\n",
    "  - $\\hat\\beta = (X^TX)^{-1}X^Ty$\n",
    "  - (or, more generally, use gradient descent to optimize the parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
